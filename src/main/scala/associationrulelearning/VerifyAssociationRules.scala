package associationrulelearning

import org.apache.spark.rdd.RDD

object VerifyAssociationRules {

  /**
   * Takes the association rules then generates their accuracy by counting occurences in the given dataset.
   * @param rules association rules generated by the algorithm
   * @param dataset all transaction where to test for accuracy
   * @return  the set of rules together with their accuracy
   */
  def verify(rules: RDD[(Set[String], Set[String], Double)], dataset: RDD[(Int, Set[String])]): RDD[(Set[String], Set[String], Double)] = {

    val rddSet: Array[Set[String]] = rules.flatMap(rule => Set(rule._1.union(rule._2), rule._1)).distinct().collect()

    val mappaSupport = dataset.flatMap(transaction =>
      rddSet.filter(s => s.subsetOf(transaction._2)).map(s => (s,1)))
      .reduceByKey((x, y) => x + y)
      .collectAsMap()

    rules.map(rule => {
      val supUnion: Double = mappaSupport(rule._1.union(rule._2))
      val supAnt: Double = mappaSupport(rule._1)
      (rule._1, rule._2, supUnion/supAnt)
    })

  }

}
