package associationrulelearning

import org.apache.spark.SparkContext


/**
 * This object runs the choosen intance of Apriori algorithm on the given dataset.
 * The dataset has to be saved in a file, given as input to this object.
 * When running, dataset, minimum support and minimum confidence must be provided following this order.
 *
 * todo: fai la conversione in Int usando un Option Type
 * todo: fai i test sui dati clusterizzati
 */
object runApriori {

  def runAprioriSeq(sc: SparkContext, filePath: String) : Unit = {

    // Creates an algorithm instance
    val alg = new AprioriSeq(filePath, 0.6, 0.7, sc)

    println("Algorithm instance created. Going to run for dataset " + filePath)
    alg.run()

    // Prints Frequent Itemsets and Association Rules generated by the algorithm
    println("===Frequent Itemsets===")
    alg.frequentItemsets.foreach(println)
    println("===Association Rules===")
    alg.associationRules.foreach(println)

  }


//  def main(args: Array[String]): Unit = {

//    if (args.size != 1) {
//      println("Dataset file must be provided in order to run Apriori")
//      System.exit(1)
//    }

//    println("Started")
//
//    val appName = "AssociationRuleLearning.AprioriSeq"
//    val master = "local" // or "local[2]"
//    val conf = new SparkConf()
//      .setAppName(appName)
//      .setMaster(master)
//    val sc = new SparkContext(conf)

    // val datasetFilePath = "src/main/resources/dataset_2010_2021_dataConversion_label.csv"

//    val alg = new AprioriSeq(datasetFilePath, 0.6, 0.7, sc)

    // Create an instance of the algorithm you want to run, then run it
//    val alg = new AprioriSeq(new File(args(0)), args(1).toInt, args(2).toInt)
//    alg.run()
//
//    // Prints Frequent Itemsets and Association Rules generated by the algorithm
//    println("===Frequent Itemsets===")
//    alg.frequentItemsets.foreach(println)
//    println("===Association Rules===")
//    alg.associationRules.foreach(println)
//  }

}
